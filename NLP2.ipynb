{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/pranjalmishra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pranjalmishra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "from gensim.parsing.preprocessing import remove_stopwords, STOPWORDS\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/pranjalmishra/Desktop/python/ipc_sections.csv', encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You entered: intentionally adulterating a drug or medical preparation to reduce its effectiveness or make it harmful, intending to sell it for medicinal purposes\n",
      "Recommended IPC(s): IPC_233, IPC_234, IPC_257, IPC_258, IPC_272, IPC_274, IPC_275, IPC_276, IPC_328, IPC_351, IPC_372, IPC_430, IPC_489D\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def spacy_preprocessing(text):\n",
    "    doc = nlp(text)\n",
    " \n",
    "    lemmatized_text = ' '.join([token.lemma_ for token in doc if token.pos_ in ['NOUN', 'ADJ', 'VERB', 'ADV']])\n",
    "   \n",
    "    tokens = [token for token in lemmatized_text.split() if token.lower() not in STOPWORDS]\n",
    "\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    non_entity_tokens = [token for token in tokens if token not in entities]\n",
    "\n",
    "    preprocessed_text = ' '.join(non_entity_tokens)\n",
    "\n",
    "    return preprocessed_text\n",
    "\n",
    "def preprocessingDesc(text):\n",
    " \n",
    "    text = re.sub(r'\\s+', ' ', text)  \n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  \n",
    "    text = text.lower()  \n",
    "    \n",
    "   \n",
    "    return spacy_preprocessing(text)\n",
    "\n",
    "df['Description'] = df['Description'].apply(preprocessingDesc)\n",
    "\n",
    "user_question = input(\"Please enter your text: \")\n",
    "print(\"You entered:\", user_question)\n",
    "preprocessed_question = preprocessingDesc(user_question)\n",
    "preprocessed_descriptions = [preprocessingDesc(desc) for desc in df['Description'].tolist()]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "description_vectors = vectorizer.fit_transform(preprocessed_descriptions)\n",
    "question_vector = vectorizer.transform([preprocessed_question])\n",
    "\n",
    "similarities = cosine_similarity(question_vector, description_vectors)\n",
    "similar_indices = np.where(similarities[0] >= 0.1)[0]  \n",
    "recommended_ipcs = df.loc[similar_indices, 'Section']\n",
    "print(\"Recommended IPC(s):\", ', '.join(map(str, recommended_ipcs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dn/t8s0kyv52pbfv6q_x3r132rw0000gn/T/ipykernel_21637/717149160.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/pranjalmishra/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pranjalmishra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You entered: I, Amit Kumar, was returning to my home on a bicycle when I met Lokesh, who was drunk, on the way. He abused and attacked me for some old thing, which caused serious injuries to my eyes and nose and on the way he also threatened to kill me\n",
      "Recommended IPC(s): Section, Punishment\n",
      "IPC Section: IPC_166, Punishment: Simple Imprisonment for 1 Year or Fine or Both\n",
      "IPC Section: IPC_152, Punishment: 3 Years or Fine or Both\n",
      "IPC Section: IPC_195A, Punishment: 7 Years or Fine or Both\n",
      "IPC Section: IPC_229, Punishment: 2 Years or Fine or Both\n",
      "IPC Section: IPC_283, Punishment: Fine\n",
      "IPC Section: IPC_300, Punishment: nan\n",
      "IPC Section: IPC_351, Punishment: nan\n",
      "IPC Section: IPC_428, Punishment: 2 Years or Fine or Both\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import torch\n",
    "import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "df = pd.read_csv('/Users/pranjalmishra/Desktop/python/ipc_sections.csv', encoding='unicode_escape')\n",
    "\n",
    "def preprocessingDesc(text):\n",
    "\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_text(text):\n",
    " \n",
    "    doc = nlp(text.lower())\n",
    "    filtered_tokens = [token.lemma_ for token in doc if token.pos_ in ['NOUN', 'VERB', 'ADJ', 'ADV'] and not token.is_stop]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "df['Processed_Description'] = df['Description'].apply(preprocessingDesc)\n",
    "\n",
    "\n",
    "user_question = input(\"Please enter your text: \")\n",
    "processed_question = preprocess_text(user_question)\n",
    "\n",
    "\n",
    "preprocessed_descriptions = [preprocess_text(desc) for desc in df['Processed_Description']]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "description_vectors = vectorizer.fit_transform(preprocessed_descriptions)\n",
    "question_vector = vectorizer.transform([processed_question])\n",
    "\n",
    "similarities = cosine_similarity(question_vector, description_vectors)\n",
    "\n",
    "similarity_threshold = 0.1\n",
    "\n",
    "similar_indices = np.where(similarities[0] >= similarity_threshold)[0]\n",
    "\n",
    "\n",
    "recommended_ipcs = df.loc[similar_indices, ['Section', 'Punishment']]\n",
    "print(\"You entered:\", user_question)\n",
    "print(\"Recommended IPC(s):\", ', '.join(map(str, recommended_ipcs)))\n",
    "\n",
    "for index, row in recommended_ipcs.iterrows():\n",
    "    print(f\"IPC Section: {row['Section']}, Punishment: {row['Punishment']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
